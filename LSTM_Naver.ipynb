{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM-Naver.ipynb의 사본의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kant1724/naver-sentiment/blob/master/LSTM_Naver.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUDazgzpKp9L",
        "colab_type": "code",
        "outputId": "29ffe708-87d4-4d09-9e9c-f67ec50d5c52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!git clone https://github.com/e9t/nsmc.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'nsmc' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlf7KxnXu3vR",
        "colab_type": "code",
        "outputId": "cb667e59-811d-483f-f290-d1254c662f56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('nsmc/ratings.txt', sep='\\t')\n",
        "train_data = pd.read_csv('nsmc/ratings_train.txt', sep='\\t')\n",
        "test_data = pd.read_csv('nsmc/ratings_test.txt', sep='\\t')\n",
        "\n",
        "train_data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9045019</td>\n",
              "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6483659</td>\n",
              "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                           document  label\n",
              "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
              "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
              "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
              "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
              "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0ZrDvf1Y_qH",
        "colab_type": "code",
        "outputId": "29c58ddd-cf58-4ffd-c767-b5585b652fa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.7.1)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.17.5)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.3)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.21.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.12.0)\n",
            "Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIWXrNooHdOi",
        "colab_type": "code",
        "outputId": "c3c94753-7938-4994-99d1-226bbe94addd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "from konlpy.tag import Okt\n",
        "okt = Okt()\n",
        "\n",
        "train_data_val = train_data['document'].values.astype(str)\n",
        "test_data_val = test_data['document'].values.astype(str)\n",
        "train_x = []\n",
        "test_x = []\n",
        "for data in tqdm(train_data_val):\n",
        "  train_x.append(okt.morphs(data))\n",
        "for data in tqdm(test_data_val):\n",
        "  test_x.append(okt.morphs(data))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 150000/150000 [05:06<00:00, 488.70it/s]\n",
            "100%|██████████| 50000/50000 [01:38<00:00, 505.28it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5pKiMW1KBUQ",
        "colab_type": "code",
        "outputId": "294346ce-1843-45d4-a677-23330358213b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1ySN54a4UKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "max_features = 50000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(train_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR4GU6YhMPzk",
        "colab_type": "code",
        "outputId": "9a696910-176e-4e77-b8c3-44df4619f72e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "maxlen = 100\n",
        "\n",
        "train_x_padded = pad_sequences(tokenizer.texts_to_sequences(train_x), maxlen=maxlen)\n",
        "test_x_padded = pad_sequences(tokenizer.texts_to_sequences(test_x), maxlen=maxlen)\n",
        "\n",
        "train_x_padded[1]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,   941,     9,   472,\n",
              "          55,   635,     3,   217,    46,  1626,    29,  1018,  6323,\n",
              "       26892], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1AT3wrYQ6D-",
        "colab_type": "code",
        "outputId": "6b126f8b-3ca9-4d90-94e6-8f6c4044bbfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "train_input = torch.LongTensor(train_x_padded)\n",
        "test_input = torch.LongTensor(test_x_padded)\n",
        "\n",
        "print(train_input)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[    0,     0,     0,  ...,    24,  7157,   688],\n",
            "        [    0,     0,     0,  ...,  1018,  6323, 26892],\n",
            "        [    0,     0,     0,  ...,   221,    18,    19],\n",
            "        ...,\n",
            "        [    0,     0,     0,  ...,    15, 17620,    17],\n",
            "        [    0,     0,     0,  ...,    11,     4, 11248],\n",
            "        [    0,     0,     0,  ...,     2,  3050,     3]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dem0I7JP630",
        "colab_type": "code",
        "outputId": "c584b79e-b02c-4b27-feb2-301f715d0e54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_target = torch.FloatTensor(train_data['label'].values)\n",
        "test_target = torch.FloatTensor(test_data['label'].values)\n",
        "\n",
        "print(train_target)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 1., 0.,  ..., 0., 1., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5N1OGPtHM9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 1\n",
        "batch_size = 512\n",
        "learning_rate = 0.001\n",
        "embedding_dim = 300\n",
        "hidden_size = 128\n",
        "num_layers = 1\n",
        "vocab_size = max_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MV82deY3KBbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GlobalMaxPooling1D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GlobalMaxPooling1D, self).__init__()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        z, _ = torch.max(inputs, 1)\n",
        "        return z\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '()'\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, embed_size, hidden_size, num_layers):\n",
        "        super(Model, self).__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_size) \n",
        "        self.proj = nn.Linear(embed_size, hidden_size)             \n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=False)        \n",
        "        self.pooling = GlobalMaxPooling1D()\n",
        "        self.linear = nn.Linear(hidden_size, hidden_size)        \n",
        "        self.dense = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.embed(x)        \n",
        "        out = torch.relu(self.proj(x))                \n",
        "        out, (h, c) = self.lstm(out)                \n",
        "        out = torch.relu(self.linear(self.pooling(out)))                        \n",
        "        out = self.dense(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def predict(self, x):\n",
        "        preds = []\n",
        "        with torch.no_grad():\n",
        "            out = self.forward(x)\n",
        "            preds.append(out)\n",
        "        return torch.cat(preds)\n",
        "\n",
        "    def predict_proba(self, x):\n",
        "        return torch.sigmoid(self.predict(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMqaiwntPMCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(embedding_dim, hidden_size, num_layers).cuda()\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBMvM2y9PMFa",
        "colab_type": "code",
        "outputId": "1245293e-d395-42bc-a617-c65a67858555",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "num_epoch = 5\n",
        "for epoch in range(num_epoch):    \n",
        "    train = torch.utils.data.TensorDataset(train_input.cuda(), train_target.cuda()) \n",
        "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=False)    \n",
        "    cnt = 0\n",
        "    for x_batch, y_batch in tqdm(train_loader, disable=True):        \n",
        "        outputs = model(x_batch)        \n",
        "        loss = criterion(np.squeeze(outputs), y_batch)\n",
        "        if cnt % 100 == 0:\n",
        "            print('epoch:' + str(epoch) + ', loss:' + str(loss))\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        cnt += 1"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:0, loss:tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "epoch:0, loss:tensor(0.4387, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "epoch:0, loss:tensor(0.3968, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "epoch:1, loss:tensor(0.3798, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "epoch:1, loss:tensor(0.3256, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "epoch:1, loss:tensor(0.3241, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "epoch:2, loss:tensor(0.3089, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "epoch:2, loss:tensor(0.2663, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "epoch:2, loss:tensor(0.2768, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "epoch:3, loss:tensor(0.2528, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "epoch:3, loss:tensor(0.2281, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "epoch:3, loss:tensor(0.2394, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "epoch:4, loss:tensor(0.1967, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "epoch:4, loss:tensor(0.1932, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "epoch:4, loss:tensor(0.2250, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRwuyiK6PMHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = []\n",
        "with torch.no_grad():\n",
        "    test = torch.utils.data.TensorDataset(test_input.cuda())    \n",
        "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
        "    for i, (x_batch,) in enumerate(test_loader):        \n",
        "        res = model.predict_proba(x_batch).cpu().numpy()\n",
        "        for re in res:          \n",
        "          out.append(re)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOOKKs2YPMN7",
        "colab_type": "code",
        "outputId": "ac88b665-af49-4749-90a0-82acf49050fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "result = []\n",
        "for o in out:\n",
        "  if o > 0.9:\n",
        "    result.append(1)\n",
        "  else:\n",
        "    result.append(0)\n",
        "\n",
        "test_label = test_data['label'].values\n",
        "\n",
        "tot_cnt = len(result)\n",
        "cnt = 0\n",
        "for i in range(len(result)):\n",
        "  if result[i] == test_label[i]:\n",
        "    cnt += 1\n",
        "\n",
        "print(cnt / tot_cnt)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.82918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PzPAscjSvyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}